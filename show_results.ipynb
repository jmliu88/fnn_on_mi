{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the description of the datasets\n",
    "<img src=\"https://raw.githubusercontent.com/wooden-knight/fnn_on_mi/master/datasets.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result table comes from the baseline paper, where miFV is the method we want to beat.\n",
    "<img src=\"https://raw.githubusercontent.com/wooden-knight/fnn_on_mi/master/sota.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                                              | musk1norm | tiger    | elephant | musk2norm | fox      |\n",
    "|--------------------------------------------------------------|-----------|----------|----------|-----------|----------|\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0000_l2norm_1_attention  | 0.767407  | 0.763333 | 0.798333 | 0.761818  | 0.518333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_1.0000_l2norm_10_attention | 0.497037  | 0.531667 | 0.52     | 0.617576  | 0.478333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.1000_l1norm_1_attention  | 0.486667  | 0.506667 | 0.49     | 0.623333  | 0.483333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.1000_l2norm_1_attention  | 0.622222  | 0.591667 | 0.506667 | 0.610303  | 0.496667 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0100_l2norm_10_attention | 0.752963  | 0.771667 | 0.768333 | 0.724242  | 0.513333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0100_l2norm_1_attention  | 0.76037   | 0.801667 | 0.773333 | 0.730303  | 0.505    |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0001_l1norm_1_attention  | 0.800741  | 0.773333 | 0.808333 | 0.752121  | 0.491667 |\n",
    "| hidden_100_rmsprop_stand_all_feat_1.0000_l2norm_1_attention  | 0.524815  | 0.518333 | 0.508333 | 0.620909  | 0.518333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0010_l1norm_1_attention  | 0.772222  | 0.795    | 0.775    | 0.769697  | 0.543333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0000_l2norm_10_attention | 0.805185  | 0.755    | 0.775    | 0.742727  | 0.533333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0010_l2norm_1_attention  | 0.764815  | 0.776667 | 0.811667 | 0.732424  | 0.523333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0001_l2norm_10_attention | 0.764444  | 0.758333 | 0.805    | 0.733333  | 0.528333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0100_l1norm_1_attention  | 0.690741  | 0.728333 | 0.601667 | 0.653636  | 0.493333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0010_l2norm_10_attention | 0.793333  | 0.743333 | 0.783333 | 0.761212  | 0.523333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_1.0000_l1norm_1_attention  | 0.551481  | 0.508333 | 0.473333 | 0.577273  | 0.485    |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0000_l1norm_1_attention  | 0.79      | 0.765    | 0.768333 | 0.728788  | 0.503333 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.1000_l2norm_10_attention | 0.624074  | 0.591667 | 0.506667 | 0.611515  | 0.496667 |\n",
    "| hidden_100_rmsprop_stand_all_feat_0.0001_l2norm_1_attention  | 0.753333  | 0.778333 | 0.785    | 0.710303  | 0.508333 |\n",
    "| 0                                                            | musk1norm | tiger    | elephant | musk2norm | fox      |\n",
    "| mean                                                         | 0.79      | 0.75     | 0.80     | 0.71      | 0.51     |\n",
    "| 0                                                            | musk1norm | tiger    | elephant | musk2norm | fox      |\n",
    "| hidden_100_dropout_0.500000_adam                             | 0.832222  | 0.7835   | 0.85     | 0.822     | 0.525    |\n",
    "| hidden_10                                                    | 0.836667  | 0.7965   | 0.8455   | 0.801     | 0.502    |\n",
    "| hidden_100_dropout_0.0_rmsprop_stand_all_feat_0.01_l2norm    | 0.866667  | 0.803    | 0.8405   | 0.812     | 0.5465   |\n",
    "| hidden_100_dropout_0.200000_rmsprop                          | 0.857778  | 0.7915   | 0.851    | 0.813     | 0.5325   |\n",
    "| hidden_100_dropout_0.500000_momentom                         | 0.674444  | 0.7225   | 0.7335   | 0.802     | 0.497    |\n",
    "| hidden_200                                                   | 0.874444  | 0.7995   | 0.8525   | 0.794     | 0.5125   |\n",
    "| hidden_100_dropout_0.0_rmsprop_stand_all_feat_0.50_l2norm    | 0.845556  | 0.809    | 0.843    | 0.801     | 0.537    |\n",
    "| hidden_100                                                   | 0.848889  | 0.8025   | 0.8545   | 0.812     | 0.5255   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explaination of the previous models are followed:\n",
    "\n",
    "|                                          |explain |\n",
    "|------------------------------------------|------------------|\n",
    "|layer_2_hidden_100_dropout_0.200000_adam | two layers with 100 hidden nodes each, dropout rate set to be 0.2, adam optimizer |\n",
    "|hidden_200| one layer with 200 nodes, without dropout, adam|\n",
    "|hidden_10| one layer with 10 nodes, without dropout, adam|\n",
    "|hidden_100_dropout_0.500000_adam| one layer with 200 nodes, dropout rate 0.5, adam|\n",
    "|hidden_100_dropout_0.500000_nesterov|one layer with 200 nodes, dropout rate 0.5, nesterov|\n",
    "|hidden_100| one layer with 100 nodes, without dropout, adam|\n",
    "|layer_2_hidden_100_dropout_0.500000_adam|two layers with 100 hidden nodes each, dropout rate 0.5, adam optimizer |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fox_100x100_matlab.mat\n",
      "200 bags\n",
      "categorical feature num 140\n",
      "musk2norm_matlab.mat\n",
      "102 bags\n",
      "categorical feature num 1\n",
      "tiger_100x100_matlab.mat\n",
      "200 bags\n",
      "categorical feature num 136\n",
      "elephant_100x100_matlab.mat\n",
      "200 bags\n",
      "categorical feature num 136\n",
      "musk1norm_matlab.mat\n",
      "92 bags\n",
      "categorical feature num 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "for iData in os.listdir('data/mat'):\n",
    "    D = io.loadmat(os.path.join('data/mat',iData))#print iData\n",
    "    feature = D['features'].todense()\n",
    "    statistic = np.empty(shape=())\n",
    "    for iFeat in range(feature.shape[1]):\n",
    "        statistic = np.append(statistic,len(np.unique(np.array(feature[:,iFeat]))))\n",
    "    print iData\n",
    "    print '%d bags'%D['bag_ids'][-1][-1]\n",
    "    print 'categorical feature num %d'%np.sum(statistic<10)#np.linspace(np.min(statistic),np.max(statistic),10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
